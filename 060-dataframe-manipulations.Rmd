# Dataframe manipulations

```{r echo = F}
options(digits=4)
```


Dataframes are ubiquitous in R-based data analyses. Many R functions and packages are tailored specifically for DF manipulations - you have already seen `cbind()`, `rbind()` and `subset()`.  
In this presentation, we'll explore a few new functions and techniques for working with DFs:

- `apply()`
- `lapply()`
- `sapply()`
- `tapply()`
- `aggregate()`
- `split()`

## The `apply()` family of functions

Looping with `for` may be tempting, but highly discouraged in R because its inefficient. Ususally one of these functions will do it better:

- `apply`: Apply a function over the "margins" of a dataframe - rows or columns or both
- `lapply`: Loop over a list and evaluate a function on each element; returns a list of the same length
- `sapply`: Same as lapply but try to simplify the result
- `tapply`: Apply a function over subsets of a vector (read: split with a factor)

There are more but these are the important ones.

### `apply()`: Apply Functions Over Array Margins

- Suppose you want to know the means of all columns of a dataframe.
- `apply()` needs to know 
    1. what DF to apply to (`X`)
    2. over which margin(s) - columns and/or rows (`MARGIN`)
    3. what function to apply (`FUN`)

```{r apply_demo}
apply(X = cars, MARGIN = 2, FUN = mean) # apply over columns
```

Here, a function is applied to both columns and rows

```{r}
df <- data.frame(x = 1:5, y = 6:10)
minus_one_squared <- function(x) (x-1)^2
apply(X = df, MARGIN = c(1,2), FUN = minus_one_squared)
```

(Ok, that was a bit lame: `minus_one_squared(df)` does the same)

The Body Mass Index, or BMI, is calculated as $(weight / height ^ 2) * 703$ where weight is in pounds and height in inches. Here it is calculated for the build in dataset `women`.

```{r apply_demo2}
head(women, n=3)
women$bmi <- apply(X = women, 
                   MARGIN = 1, 
                   FUN = function(x) (x[2] / x[1]^2) * 703)
head(women, n=4)
```

#### Pass arguments to the applied function {-}

Sometimes the applied function needs to have other arguments passed besides the row or column. The `...` argument to `apply()` makes this possible (type `?apply` to see more info)

```{r}
# function sums and powers up
spwr <- function(x, p = 2) {sum(x)^p}
# a simple dataframe
df <- data.frame(a = 1:5, b = 6:10)
df
# spwr will use the default value for p (p = 2)
apply(X = df, MARGIN = 1, FUN = spwr) 
# pass power p = 3 to function spwr (argument names omitted)
apply(df, 1, spwr, p = 3) 
```

Note: The `...` argument works for all `..apply..` functions.

### `lapply()`: Apply a Function over a List or Vector

Function `lapply()` applies a function to all elements of a list and returns a list with the same length, each element the result of applying the function

```{r lapply_demo1}
myNumbers = list(
    one = c(1, 3, 4), 
    two = c(3, 2, 6, 1), 
    three = c(5, 7, 6, 8, 9))
lapply(X = myNumbers, FUN = mean)
```


Here is the same list, but now with `sqrt()` applied. Notice how the nature of the applied function influences the result.

```{r lapply_demo2}
lapply(X = myNumbers, FUN = sqrt)
```


### `sapply()`: Apply a Function over a List or Vector and Simplify

When using the same example as above, but with `sapply`, you get a vector returned. Note that the resulting vector is a named vector, a convenient feature of `sapply` 

```{r sapply_demo}
myNumbers = list(
    one = c(1, 3, 4),
    two = c(3, 2, 6, 1),
    three = c(5, 7, 6, 8, 9))
sapply(X = myNumbers, FUN = mean)
```

When the result can not be simplified, you get the same list as with `lapply()`:

```{r}
sapply(X = myNumbers, FUN = sqrt)
```

#### wasn't a dataframe also a list?

Yes! It is also list(ish). Both `lapply()` and `sapply()` work just fine on dataframes:

```{r df-is-also-list}
lapply(X = cars, FUN = mean)
sapply(X = cars, FUN = mean) 
```

By the way, sapply and lapply also work with vectors.

### `tapply()`: Apply a Function Over a Ragged Array

What `tapply()` does is apply a function over subsets of a vector; it splits a vector into groups according to the levels in a second vector and applies the given function to each group.

```{r tapply_demo}
tapply(X = chickwts$weight, INDEX = chickwts$feed, FUN = sd)
```


### `split()`: Divide into Groups and Reassemble

This is similar to `tapply()` in the sense that is uses a factor to split its first argument. But where `tapply()` splits a vector, `split()` splits a dataframe - into _list of dataframes_.
You use `split()` when a dataframe needs to be divided depending on the value of some grouping variable.  
Here we have the response of Treated (T) and Untreated (UT) subjects

```{r split_demo1}
myData <- data.frame(
    response = c(5, 8, 4, 5, 9, 3, 6, 7, 3, 6, 5, 2),
    treatment = factor(
        c("UT", "T", "UT", "UT", "T", "UT", "T", "T", "UT", "T", "T", "UT")))
splData <- split(x = myData, f = myData$treatment)
str(splData)
boxplot(splData$T$response, splData$UT$response, 
        names = c("Treated", "Untreated"))
```

Note that this trivial example could also have been done with `boxplot(myData$response ~ myData$treatment)`.

Here you can see that `split()` also works with vectors.

```{r}
split(x = rnorm(10), f = rep(c("sick", "healthy"), each=5))
```

### `aggregate()`: Compute Summary Statistics of Data Subsets

Splits the data into subsets, computes summary statistics for each, and returns the result in a convenient form.

```{r}
aggregate(formula = Temp ~ Month, data = airquality, FUN = mean)
```

Aggregate has two usage techniques:  

- with a formula:  
  **`aggregate(formula, data, FUN, ...)`**  

- with a list:  
  **`aggregate(x, by, FUN, ...)`**  

I really like `aggregate()`, especially the first form. That is, until I got to know the `dplyr` package.

Both forms of `aggregate()` will be demonstrated

#### Aggregate with formula {-}

The left part of the formula accepts one, several or all columns as dependent variables.

```{r}
##two dependents
aggregate(cbind(Temp, Ozone) ~ Month, data = airquality, FUN = mean)
##all
aggregate(. ~ Month, data = airquality, FUN = mean)
```


The right part can also accept multiple independent variables


```{r}
airquality$Temp_factor <- cut(airquality$Temp, breaks = 2, labels = c("low", "high"))
aggregate(Ozone ~ Month + Temp_factor, data = airquality, FUN = mean)
```

#### The `by = list(...)` form {-}

This is the other form of aggregate. It is more elaborate in my opinion because you need te spell out all vectors you want to work on.

```{r}
aggregate(x = chickwts$weight, by = list(feed = chickwts$feed), FUN = mean)
```

Here is another example:

```{r}
aggregate(x = airquality$Wind, 
          by = list(month = airquality$Month, temperature = airquality$Temp_factor), 
          FUN = mean)
```

But it is better to wrap it in `with()`:

```{r eval=FALSE}
with(airquality, aggregate(x = Wind, 
                           by = list(month = Month, temperature = Temp_factor), 
                           FUN = mean))
```

### Many roads lead to Rome

The next series of examples are all essentially the same. The message is: there is more than one way to do it!

```{r}
aggregate(weight ~ feed, data = chickwts, FUN = mean)
```

same as

```{r}
head(aggregate(x = chickwts$weight, by = list(feed = chickwts$feed), FUN = mean), n=3)
```

same as

```{r message=FALSE}
tapply(chickwts$weight, chickwts$feed, mean)
with(chickwts, tapply(weight, feed, mean))
```

same as

```{r }
sapply(split(chickwts, chickwts$feed), function(x){mean(x$weight)})
```

And this is the topic of the next course:

```{r message=FALSE}
library(dplyr)
group_by(chickwts, feed) %>% summarise(mean_weigth = mean(weight))
```

## Example Use Cases {#usecases}

In this chapter, some example use cases will be presented demonstrating some concept or function.
The topics for these use cases are selected because they appear to be harder to comprehend for my students, are a bit out of scope for the lectures, or because they are simply too extensive to fit into a few slides of a presentation.  

### Dataframe Selections {#dfselection}

R offers a wealth of methods to make selection on dataframes by columns, rows, or both.

We'll explore the `iris` dataset, a dataframe holding morphological data on several species of plants from the genus _Iris_:

```{r iris_table}
knitr::kable(head(iris, 10))
```

There are only three species in this dataset

```{r show_iris_species}
table(iris$Species)
```

but how do they relate to each other with repect to Sepal length?

```{r boxplot_sepal_length}
with(iris, boxplot(Sepal.Length ~ Species,
                   ylab = "Sepal length (cm)",
                   xlab = "Iris species"))
```

Now suppose I want to get the data from _virginica_ plants that have a Sepal length smaller than the largest Sepal length of _setosa_ plants?
First of course we'll need the maximum of the _setosa_ plants:

```{r get_max_sepal}
max.setosa <- max(iris[iris$Species == "setosa", "Sepal.Length"])
max.setosa
```

Which plant is it? Let's use the subset function to find out.

```{r get_max_sepal_plant}
subset(x = iris,
       subset = (Species == "setosa" & Sepal.Length == max.setosa))
```

Now filter out the _virginica_ plants that have a Sepal length smaller than this value. I'll show two approaches, one with logical indexing and one with `subset`

```{r get_small_virginicas_logical}
##get a logical for small plants
logi.small.sepal <- iris$Sepal.Length < max.setosa
logi.small.sepal
##get a logical for virginica plants
logi.virginica <- iris$Species == "virginica"
logi.virginica
##combine the two via a boolean operation
logi.both <- logi.small.sepal & logi.virginica
logi.both
##use it as a selector on the rows of the iris DF
iris[logi.both, ]
```

Of course, you will usually perform this selection in one statement, but the operations carried out by R will be exactly the same (but without creating any variables of course):

```{r get_small_virginicas_fast}
iris[iris$Sepal.Length < max.setosa & iris$Species == "virginica", ]
```

The function `subset` will do the same behind the scenes, but your code may be more to your liking:

```{r get_small_virginicas_subset}
subset(x = iris,
       subset = Sepal.Length < max.setosa & Species == "virginica")
```

By the way, **beware to use only one boolean and: &, not &&**. This will not give an error but only an empty result set

```{r get_small_virginicas_subset_two_ands}
subset(x = iris,
       subset = Sepal.Length < max.setosa && Species == "virginica")
```

> & and && indicate logical AND and | and || indicate logical OR. The shorter form performs elementwise comparisons in much the same way as arithmetic operators. The longer form evaluates left to right examining only the first element of each vector. Evaluation proceeds only until the result is determined. The longer form is appropriate for programming control-flow and typically preferred in if clauses.  

Can you figure out why using `&&` would give an empty set in the above case?

See [The R manual](http://stat.ethz.ch/R-manual/R-patched/library/base/html/Logic.html) for details.


### Apply {#apply}

Consider the `women` dataset, holding height and weight of a population sample of 15 women:

```{r women_table}
knitr::kable(women)
```

To calculate the average height and the average weight of this sample, one could of course simply do 

```{r naive_means}
with(women, {
    print(mean(height))
    print(mean(weight))
})
```

However, when your dataset has (a lot) more columns, repeating this will be quite tedious...unless you use a `for` loop

```{r means_with_for}
for (i in 1:length(women)) {
    print(mean(women[,i]))
}
```

Enter `apply()`, a very nice function to do this in a handy one-liner

```{r means_with_apply}
apply(X = women, MARGIN = 2, FUN = mean)
```

The arguments I supplied to `apply`have the following purpose:  

1. `X = women` specifies the data to be processed
2. `MARGIN = 2` specifies wether columns or rows shoud be processed; 1 = rows and 2 = columns
3. `FUN = mean` speciefies the function to be applied to the given dataframe


Not only gives apply the the exact same result (of course, duh), but this approach has several advantages:

- `apply` returns a named vector where the elements are named the same as the corresponding columns of the original dataframe
- `apply` is computationally more efficient than the other approaches
- it requires less code; a good programmer types as little as possible - except for Java programmers of course :-)

If you really have strongh feelings about typing no more than strictly required, you can of course also omit the method parameters:

```{r means_with_apply_noargs}
apply(women, 2, mean)
```

But if you are just starting out with R, I suggest you invest those few character strokes for readability later on.

The above example dealt with columns. For instance, if you want to calculate the BMI of these women, you'll need to target the rows.
The BMI formula is 
$$weight/height^2*703$$

where weight is in pounds and height is in inches.

This formula is implemented in the following function.

```{r bmi_function}
bmi <- function(height, weight) {
    (weight / height^2) * 703
}
bmi(65, 150)
```

You can also apply the formula to the `women` dataset:

```{r calculate_bmi1}
women$bmi1 <- apply(
    X = women, 
    MARGIN = 1, 
    FUN = function(x){(x[2] / x[1]^2) * 703})
head(women, n = 4)
```

if you like to use your own formula (it's always a good idea to write logic only once and reuse it in different places), you'll still need to wrap it inside an anonymous function call:

```{r calculate_bmi2}
women$bmi2 <- apply(
    X = women, 
    MARGIN = 1, 
    FUN = function(x){bmi(x[1], x[2])})
head(women, n = 4)
```


### Processing Embedded Dataframes {#embeddeddf}

Suppose you have imported some data that has a structure like this

```{r embedded_df_data}
genes <- c("gene A", "gene B", "gene C", "gene D")
positions <- c("chr01:128757:129667", 
               "chr01:366389:486990",
               "chr02:8986463:9100856",
               "chr03:53536:87201")
my.genome <- data.frame(gene = genes, position = positions)
my.genome
```

The problem here is that the second column, `positions`, of type `character`, actually holds three different variables: the chromosome identifyer, the start position and the stop position on the chromosome. To be able to perform analyses of chromosomal contents, or positional contexts, we will need to split this column into separate columns, each holding exactly one variable of the correct type (`factor`, `integer` and `integer`).

When I first encountered this type of problem (it is a _challenge_ actually, some teachers would object, not a _problem_...), my first thought was "easy, simply apply a split and bind as three columns".

Let's have a look at how the `strsplit` function works in splitting strings

```{r strsplit_demo}
strsplit(x = positions[1:2], split = ":")
```

As you can see, strsplit generates a list of vectors, with each vector corresponding to the string at the same index of the original character vector.
So, easy, I thought. Simply assign these elements to three new columns of the original dataframe (assuming every split character results in a vector of three). I first created the columns, defined my splitter function and then used apply to get the job done

```{r assign_new_columns}
## create columns
my.genome[, c("chromosome", "start", "stop")] <- NA
## define splitter function
loc.splitter <- function(x) {
    ## strsplit returns a list!
    strsplit(x["position"], ":")[[1]]
}
## use apply to fill the columns
my.genome[, 3:5] <- apply(X = my.genome,
                          MARGIN = 1,
                          FUN = loc.splitter)
my.genome
```

Whoa, what happened here?! This was not what I had in mind. Can you figure out what happened?

...

I did figure it out (eventually...). The applied function returned three elements at a time, and I had apply fill three columns of my dataframe. And that is exactly what R did, fill the three columns, but not by row but by column! Have a look at the output from apply and you can see:

```{r apply_split_result}
apply(X = my.genome,
      MARGIN = 1,
      FUN = loc.splitter)
```

Fortunately, R has a function to transpose this kind of structure (a matrix actually): the `t()` function, so that is what I did:

```{r apply_and_transpose}
my.genome[, 3:5] <- t(apply(X = my.genome,
                            MARGIN = 1,
                            FUN = loc.splitter))
my.genome
```

Yeah, that's what I'm talking about! (Feeling very happy with myself...until I googled this problem). I found out there are a gazillion solutions to this problem, but only one of them is very very simple, because it uses a function you know really well: `read.table`, but not with the `file = ` argument but with `text = `:

```{r do_it_easy}
my.genome <- data.frame(gene = genes, position = positions)
my.genome <- cbind(
    my.genome,
    read.table(
        text = as.character(my.genome$position),
        sep = ":"))
colnames(my.genome) <- c(colnames(my.genome)[1:2], "chr", "start", "stop")
my.genome
```

That's it. The lessons learned here:  

- Always know that GIYF (Google Is Your Friend)
- When reading tables, also those embedded within others, use `read.table`
- You really learn a lot by fiddling about with data

